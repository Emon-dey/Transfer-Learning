Current experiment parameters:
{'n_channels': 3, 'n_classes': 11, 'batch_size': 32, 'batch_size_eval': 1024, 'window_size': 128, 'window_offset': 8, 'source_epochs': 10, 'target_epochs': 10, 'n_iter': 20000, 'seed': 0, 'log_interval': 100, 'eval_interval': 500, 'gpu': '0', 'mode': 'prune', 'lr_FCs': 0.002, 'lr_FCs_b1': 0.9, 'lr_FCs_b2': 0.999, 'lr_FCt': 0.0002, 'lr_FCt_b1': 0.9, 'lr_FCt_b2': 0.999, 'w_conv1': 0.5, 'w_conv2': 0.05, 'w_conv3': 0.005, 'w_fc1': 0.001, 'w_fc2': 0.0001, 'log': 'default.csv', 'log_train': 'log_train.csv', 'dataset': 'PAMAP2', 'subject_source': 'subject105', 'subject_target': 'subject106', 'position_source': 'c', 'position_target': 'h', 'scaling': True}
Train Epoch: 1 [0/12161 (0%)]	Loss: 2.619565
Train Epoch: 1 [3200/12161 (26%)]	Loss: 0.903018
Train Epoch: 1 [6400/12161 (53%)]	Loss: 0.826943
Train Epoch: 1 [9600/12161 (79%)]	Loss: 0.522195
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000466] [acc: 10435/12161 (85.81%)] [f1: 0.8581]
TARGET w/o tranfer: [loss: 0.010919] [acc: 312/2763 (11.29%)] [f1: 0.1129]
--------------------------------------------------------------------------------
Train Epoch: 2 [0/12161 (0%)]	Loss: 0.465274
Train Epoch: 2 [3200/12161 (26%)]	Loss: 0.135410
Train Epoch: 2 [6400/12161 (53%)]	Loss: 0.275035
Train Epoch: 2 [9600/12161 (79%)]	Loss: 0.907826
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000355] [acc: 10753/12161 (88.42%)] [f1: 0.8842]
TARGET w/o tranfer: [loss: 0.006603] [acc: 365/2763 (13.21%)] [f1: 0.1321]
--------------------------------------------------------------------------------
Train Epoch: 3 [0/12161 (0%)]	Loss: 0.280322
Train Epoch: 3 [3200/12161 (26%)]	Loss: 0.439030
Train Epoch: 3 [6400/12161 (53%)]	Loss: 0.359254
Train Epoch: 3 [9600/12161 (79%)]	Loss: 0.364359
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000377] [acc: 10710/12161 (88.07%)] [f1: 0.8807]
TARGET w/o tranfer: [loss: 0.012452] [acc: 320/2763 (11.58%)] [f1: 0.1158]
--------------------------------------------------------------------------------
Train Epoch: 4 [0/12161 (0%)]	Loss: 0.524078
Train Epoch: 4 [3200/12161 (26%)]	Loss: 0.387553
Train Epoch: 4 [6400/12161 (53%)]	Loss: 0.317502
Train Epoch: 4 [9600/12161 (79%)]	Loss: 0.265459
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000353] [acc: 10704/12161 (88.02%)] [f1: 0.8802]
TARGET w/o tranfer: [loss: 0.016260] [acc: 446/2763 (16.14%)] [f1: 0.1614]
--------------------------------------------------------------------------------
Train Epoch: 5 [0/12161 (0%)]	Loss: 0.362262
Train Epoch: 5 [3200/12161 (26%)]	Loss: 0.461267
Train Epoch: 5 [6400/12161 (53%)]	Loss: 0.076715
Train Epoch: 5 [9600/12161 (79%)]	Loss: 0.751867
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000356] [acc: 10742/12161 (88.33%)] [f1: 0.8833]
TARGET w/o tranfer: [loss: 0.011730] [acc: 482/2763 (17.44%)] [f1: 0.1744]
--------------------------------------------------------------------------------
Train Epoch: 6 [0/12161 (0%)]	Loss: 0.128616
Train Epoch: 6 [3200/12161 (26%)]	Loss: 0.336226
Train Epoch: 6 [6400/12161 (53%)]	Loss: 0.229897
Train Epoch: 6 [9600/12161 (79%)]	Loss: 0.557212
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000286] [acc: 11042/12161 (90.80%)] [f1: 0.9080]
TARGET w/o tranfer: [loss: 0.017137] [acc: 430/2763 (15.56%)] [f1: 0.1556]
--------------------------------------------------------------------------------
Train Epoch: 7 [0/12161 (0%)]	Loss: 0.169536
Train Epoch: 7 [3200/12161 (26%)]	Loss: 0.391834
Train Epoch: 7 [6400/12161 (53%)]	Loss: 0.161281
Train Epoch: 7 [9600/12161 (79%)]	Loss: 0.037316
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000301] [acc: 10987/12161 (90.35%)] [f1: 0.9035]
TARGET w/o tranfer: [loss: 0.013326] [acc: 362/2763 (13.10%)] [f1: 0.1310]
--------------------------------------------------------------------------------
Train Epoch: 8 [0/12161 (0%)]	Loss: 0.309477
Train Epoch: 8 [3200/12161 (26%)]	Loss: 0.313540
Train Epoch: 8 [6400/12161 (53%)]	Loss: 0.422986
Train Epoch: 8 [9600/12161 (79%)]	Loss: 0.338971
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000279] [acc: 11018/12161 (90.60%)] [f1: 0.9060]
TARGET w/o tranfer: [loss: 0.014324] [acc: 321/2763 (11.62%)] [f1: 0.1162]
--------------------------------------------------------------------------------
Train Epoch: 9 [0/12161 (0%)]	Loss: 0.514799
Train Epoch: 9 [3200/12161 (26%)]	Loss: 0.242287
Train Epoch: 9 [6400/12161 (53%)]	Loss: 0.202102
Train Epoch: 9 [9600/12161 (79%)]	Loss: 0.358841
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000319] [acc: 10795/12161 (88.77%)] [f1: 0.8877]
TARGET w/o tranfer: [loss: 0.010862] [acc: 435/2763 (15.74%)] [f1: 0.1574]
--------------------------------------------------------------------------------
Train Epoch: 10 [0/12161 (0%)]	Loss: 0.133713
Train Epoch: 10 [3200/12161 (26%)]	Loss: 0.568316
Train Epoch: 10 [6400/12161 (53%)]	Loss: 0.137772
Train Epoch: 10 [9600/12161 (79%)]	Loss: 0.195262
--------------------------------------------------------------------------------
SOURCE            : [loss: 0.000197] [acc: 11360/12161 (93.41%)] [f1: 0.9341]
TARGET w/o tranfer: [loss: 0.013432] [acc: 431/2763 (15.60%)] [f1: 0.1560]
--------------------------------------------------------------------------------
[Epoch 1/10] [Iter 0/2763]	[Losses conv1: 26.8479 | conv2: 157.0024 | conv3: 123.3987 | final: 3.91103244]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.001387] [acc: 1758/2763 (63.63%)] [f1: 0.6363]
--------------------------------------------------------------------------------
[Epoch 2/10] [Iter 0/2763]	[Losses conv1: 12.4059 | conv2: 126.6254 | conv3: 94.7424 | final: 1.44106650]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000974] [acc: 2037/2763 (73.72%)] [f1: 0.7372]
--------------------------------------------------------------------------------
[Epoch 3/10] [Iter 0/2763]	[Losses conv1: 12.2150 | conv2: 134.4043 | conv3: 133.9700 | final: 0.80995965]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000723] [acc: 2139/2763 (77.42%)] [f1: 0.7742]
--------------------------------------------------------------------------------
[Epoch 4/10] [Iter 0/2763]	[Losses conv1: 31.4701 | conv2: 94.7191 | conv3: 111.7412 | final: 0.53644800]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000620] [acc: 2232/2763 (80.78%)] [f1: 0.8078]
--------------------------------------------------------------------------------
[Epoch 5/10] [Iter 0/2763]	[Losses conv1: 13.2398 | conv2: 113.6467 | conv3: 92.9167 | final: 0.36163646]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000600] [acc: 2244/2763 (81.22%)] [f1: 0.8122]
--------------------------------------------------------------------------------
[Epoch 6/10] [Iter 0/2763]	[Losses conv1: 27.9541 | conv2: 94.8725 | conv3: 97.3129 | final: 1.51296759]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000410] [acc: 2463/2763 (89.14%)] [f1: 0.8914]
--------------------------------------------------------------------------------
[Epoch 7/10] [Iter 0/2763]	[Losses conv1: 23.7712 | conv2: 89.2734 | conv3: 79.1469 | final: 0.52008688]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000381] [acc: 2455/2763 (88.85%)] [f1: 0.8885]
--------------------------------------------------------------------------------
[Epoch 8/10] [Iter 0/2763]	[Losses conv1: 10.0533 | conv2: 75.3312 | conv3: 78.5273 | final: 0.30238923]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000337] [acc: 2466/2763 (89.25%)] [f1: 0.8925]
--------------------------------------------------------------------------------
[Epoch 9/10] [Iter 0/2763]	[Losses conv1: 17.4092 | conv2: 77.0514 | conv3: 86.7486 | final: 0.15096648]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000289] [acc: 2528/2763 (91.49%)] [f1: 0.9149]
--------------------------------------------------------------------------------
[Epoch 10/10] [Iter 0/2763]	[Losses conv1: 9.9044 | conv2: 70.0703 | conv3: 92.6817 | final: 0.12883326]
--------------------------------------------------------------------------------
TARGET with tranfer: [loss: 0.000322] [acc: 2480/2763 (89.76%)] [f1: 0.8976]
--------------------------------------------------------------------------------
TARGET FULL SET: [loss: 0.183889] [acc: 3991/11072 (36.05%)] [f1: 0.3605]
